import streamlit as st
from openai import OpenAI
import json
import os
import PyPDF2
from docx import Document
import moviepy.editor as mp
from tempfile import NamedTemporaryFile
import io
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import landscape, A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
MODEL_GPT = "gpt-4o"
MODEL_WHISPER = "whisper-1"

class QuizQuestion:
    def __init__(self, scenario, options, correct_option_id, explanation=""):
        self.scenario = scenario
        self.options = options
        self.correct_option_id = correct_option_id
        self.explanation = explanation

class Quiz:
    def __init__(self, questions):
        self.questions = questions

def get_client(api_key):
    return OpenAI(api_key=api_key)

# --- 1. –û–ë–†–ê–ë–û–¢–ö–ê –§–ê–ô–õ–û–í ---
def process_file_to_text(uploaded_file, api_key):
    client = get_client(api_key)
    file_ext = uploaded_file.name.split('.')[-1].lower()
    text_content = ""

    try:
        # PDF
        if file_ext == 'pdf':
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            for page in pdf_reader.pages: text_content += page.extract_text() + "\n"
        
        # DOCX
        elif file_ext in ['docx', 'doc']:
            doc = Document(uploaded_file)
            text_content = "\n".join([para.text for para in doc.paragraphs])
        
        # TEXT
        elif file_ext == 'txt':
            text_content = uploaded_file.getvalue().decode("utf-8")
        
        # –í–ò–î–ï–û –ò –ê–£–î–ò–û (–ì–õ–ê–í–ù–ê–Ø –ß–ê–°–¢–¨)
        elif file_ext in ['mp4', 'mov', 'avi', 'mkv', 'mp3', 'wav', 'm4a', 'mpeg4', 'webm', 'wmv']:
            with st.status("üé¨ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ/–∞—É–¥–∏–æ...", expanded=True) as status:
                status.write("1. –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É...")
                text_content = transcribe_audio_video(uploaded_file, client, status)
                status.update(label="‚úÖ –ì–æ—Ç–æ–≤–æ!", state="complete", expanded=False)

    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        return ""

    if not text_content:
        st.warning("‚ö†Ô∏è –¢–µ–∫—Å—Ç –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω. –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ –≤–∏–¥–µ–æ –±–µ–∑ –∑–≤—É–∫–∞.")
    
    return text_content

def transcribe_audio_video(uploaded_file, client, status_container):
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        suffix = f".{uploaded_file.name.split('.')[-1]}"
        with NamedTemporaryFile(delete=False, suffix=suffix) as tmp_video:
            tmp_video.write(uploaded_file.getvalue())
            tmp_video_path = tmp_video.name

        audio_path = tmp_video_path + "_converted.mp3"
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ MoviePy (—Ç—Ä–µ–±—É–µ—Ç FFMPEG)
        status_container.write("2. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç MP3 (32kbps)...")
        
        if suffix.lower() in ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.wmv', '.mpeg4']:
            video = mp.VideoFileClip(tmp_video_path)
            # –ï—Å–ª–∏ –≤–∏–¥–µ–æ –¥–ª–∏–Ω–Ω–µ–µ 20 –º–∏–Ω—É—Ç - —Ä–µ–∂–µ–º
            if video.duration > 1200: 
                status_container.warning(f"–í–∏–¥–µ–æ –¥–ª–∏–Ω–Ω–æ–µ ({int(video.duration)}—Å). –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 20 –º–∏–Ω.")
                video = video.subclip(0, 1200)
            
            video.audio.write_audiofile(audio_path, bitrate="32k", logger=None)
            video.close()
        else:
            # –ê—É–¥–∏–æ —Ç–æ–∂–µ –ø—Ä–æ–≥–æ–Ω—è–µ–º —á–µ—Ä–µ–∑ –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –¥–ª—è —Å–∂–∞—Ç–∏—è
            audio_clip = mp.AudioFileClip(tmp_video_path)
            audio_clip.write_audiofile(audio_path, bitrate="32k", logger=None)
            audio_clip.close()

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        size_mb = os.path.getsize(audio_path) / (1024*1024)
        status_container.write(f"3. –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Whisper AI ({size_mb:.1f} MB)...")

        if size_mb > 24:
            st.error("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π (>25MB) –¥–∞–∂–µ –ø–æ—Å–ª–µ —Å–∂–∞—Ç–∏—è.")
            return ""

        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model=MODEL_WHISPER, file=audio_file, response_format="text"
            )
        
        # –ß–∏—Å—Ç–∫–∞
        try: os.remove(tmp_video_path); os.remove(audio_path)
        except: pass
        
        return transcript

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ (FFMPEG/Whisper): {str(e)}")
        if "ffmpeg" in str(e).lower():
            st.error("üö® –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ –Ω–µ –Ω–∞–π–¥–µ–Ω FFMPEG. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: sudo apt install ffmpeg")
        return ""

# --- 2. –ì–ï–ù–ï–†–ê–¶–ò–Ø –¢–ï–°–¢–ê ---
def generate_quiz_ai(text, num_questions, difficulty, language):
    client = get_client(st.secrets["OPENAI_API_KEY"])
    if not text: return Quiz([])
    
    prompt = f"""
You are an expert quiz creator. Create an engaging quiz based on the following text.

TEXT:
{text[:25000]}

REQUIREMENTS:
- Language: {language}
- Difficulty: {difficulty}
- Number of questions: {num_questions}
- Each question must have exactly 4 options
- Include a brief explanation (1-2 sentences) for why the correct answer is right

OUTPUT FORMAT (strict JSON):
{{
  "questions": [
    {{
      "scenario": "Question text here?",
      "options": ["Option A", "Option B", "Option C", "Option D"],
      "correct_option_id": 0,
      "explanation": "Brief explanation why this answer is correct."
    }}
  ]
}}
"""
    try:
        response = client.chat.completions.create(
            model=MODEL_GPT,
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"}
        )
        data = json.loads(response.choices[0].message.content)
        return Quiz([QuizQuestion(q['scenario'], q['options'], q['correct_option_id'], q.get('explanation', '')) for q in data['questions']])
    except Exception as e: return Quiz([QuizQuestion(f"Error: {e}", ["OK"], 0)])

def generate_methodologist_hints(text, language):
    if not text: return "–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞."
    client = get_client(st.secrets["OPENAI_API_KEY"])
    try:
        res = client.chat.completions.create(
            model=MODEL_GPT, messages=[{"role": "user", "content": f"3 learning tips for: {text[:5000]}. Lang: {language}"}]
        )
        return res.choices[0].message.content
    except: return "–°–æ–≤–µ—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã."

# --- 3. –≠–ö–°–ü–û–†–¢ ---
def create_html_quiz(quiz_obj, filename):
    js_data = []
    for q in quiz_obj.questions:
        js_data.append({"question": q.scenario, "options": q.options, "correct": q.correct_option_id})
    json_str = json.dumps(js_data)
    
    html = f"""
    <!DOCTYPE html>
    <html><head><meta charset='UTF-8'><style>body{{font-family:sans-serif;padding:20px;max-width:800px;margin:0 auto}} .card{{border:1px solid #ccc;padding:15px;margin-bottom:15px;border-radius:8px}} .btn{{background:#007bff;color:white;padding:10px 20px;border:none;cursor:pointer}} .correct{{color:green;font-weight:bold}} .wrong{{color:red;font-weight:bold}}</style></head>
    <body><h1>Test: {filename}</h1><div id="q"></div><button class="btn" onclick="check()">Check</button><h2 id="sc"></h2>
    <script>const d={json_str}; function r(){{let h='';d.forEach((q,i)=>{{h+=`<div class='card'><h3>${{i+1}}. ${{q.question}}</h3>`;q.options.forEach((o,j)=>{{h+=`<label style='display:block'><input type='radio' name='q${{i}}' value='${{j}}'> ${{o}}</label>`}});h+=`<div id='r${{i}}'></div></div>`}});document.getElementById('q').innerHTML=h}} r();
    function check(){{let s=0;d.forEach((q,i)=>{{let el=document.querySelector(`input[name='q${{i}}']:checked`);let r=document.getElementById(`r${{i}}`);if(el&&parseInt(el.value)===q.correct){{s++;r.innerHTML="<span class='correct'>OK</span>"}}else{{r.innerHTML=`<span class='wrong'>Wrong. Answer: ${{q.options[q.correct]}}</span>`}}}});document.getElementById('sc').innerText=`Score: ${{s}}/${{d.length}}`}}</script></body></html>
    """
    return html.encode('utf-8')

def create_certificate(student_name, course_name, logo_file=None):
    buffer = io.BytesIO()
    c = canvas.Canvas(buffer, pagesize=landscape(A4))
    width, height = landscape(A4)
    c.setLineWidth(5); c.rect(30,30,width-60,height-60)
    c.setFont("Helvetica-Bold", 40); c.drawCentredString(width/2, height-150, "CERTIFICATE")
    c.setFont("Helvetica", 20); c.drawCentredString(width/2, height-220, "OF COMPLETION")
    c.setFont("Helvetica-Bold", 30); c.drawCentredString(width/2, height-300, student_name)
    c.setFont("Helvetica-Oblique", 20); c.drawCentredString(width/2, height-380, course_name)
    c.save()
    buffer.seek(0)
    return buffer.getvalue()

# --- –¢–†–ê–ù–°–ö–†–ò–ü–¶–ò–Ø –î–õ–Ø –ë–û–¢–ê (–ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É) ---
def transcribe_for_bot(file_path):
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª—è Telegram –±–æ—Ç–∞ - –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É"""
    try:
        import os
        from openai import OpenAI
        
        client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ mp3 (–µ—Å–ª–∏ —ç—Ç–æ –≤–∏–¥–µ–æ)
        audio_path = file_path + "_converted.mp3"
        
        if file_path.lower().endswith(('.mp4', '.mov', '.avi', '.mkv', '.webm')):
            video = mp.VideoFileClip(file_path)
            if video.duration > 1200:
                video = video.subclip(0, 1200)
            video.audio.write_audiofile(audio_path, bitrate="32k", logger=None)
            video.close()
        else:
            # –ê—É–¥–∏–æ - —Ç–æ–∂–µ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è —Å–∂–∞—Ç–∏—è
            audio_clip = mp.AudioFileClip(file_path)
            audio_clip.write_audiofile(audio_path, bitrate="32k", logger=None)
            audio_clip.close()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        size_mb = os.path.getsize(audio_path) / (1024*1024)
        if size_mb > 24:
            return "Error: File too large"
        
        # Whisper
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1", file=audio_file, response_format="text"
            )
        
        # –ß–∏—Å—Ç–∫–∞
        try: 
            os.remove(file_path)
            os.remove(audio_path)
        except: pass
        
        return transcript
        
    except Exception as e:
        return f"Error: {str(e)}"
